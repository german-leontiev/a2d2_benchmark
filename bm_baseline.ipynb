{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e7ea8a2-0d10-4b8b-a501-0be37ef8d2d5",
   "metadata": {},
   "source": [
    "### Import libs, global variables and pickled files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba04c81c-14ce-48f8-9385-b1de128cf4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle, os, cv2, random, tqdm, json\n",
    "from random import choice as r_ch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from os.path import join as join_path\n",
    "from os.path import sep as os_sep\n",
    "from os.path import exists as path_exists\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import albumentations as album\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "from global_names import A2D2_PATH\n",
    "\n",
    "\n",
    "with open(\"bm_ds.pkl\", \"rb\") as f:\n",
    "    bm_ds = pickle.load(f)\n",
    "    \n",
    "# Load files\n",
    "with open(join_path(A2D2_PATH, \"camera_lidar_semantic\", \"class_list.json\"), \"rb\") as f:\n",
    "     class_list= json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9a7a8c-1d12-4e88-a431-471a9a3716f3",
   "metadata": {},
   "source": [
    "### Define functions for getting paths from ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d32b6aad-6fb9-47c0-ae25-d5bc662cd26d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ss_p = join_path(A2D2_PATH, \"camera_lidar_semantic\")\n",
    "\n",
    "sens_ext = {\n",
    "    \"camera\": \".png\",\n",
    "    \"label\": \".png\",\n",
    "    \"lidar\": \".npz\"\n",
    "}\n",
    "\n",
    "rel_ = lambda __p: join_path(*__p.split(os_sep)[__p.split(os_sep).index('camera_lidar_semantic'):])\n",
    "abs_ = lambda __p: join_path(A2D2_PATH, __p)\n",
    "\n",
    "def sensor_p(_id, s_type):\n",
    "    if s_type not in sens_ext.keys(): raise ValueError(\"Wrong sensor type: s_type\")\n",
    "    d,t,s = _id.split(\"_\")\n",
    "    _p = \"_\".join([d, s_type, s, t]) + sens_ext[s_type]\n",
    "    _p = join_path(ss_p, f\"{d[:8]}_{d[8:]}\", s_type, f\"cam_{sa_(s)}\", _p)\n",
    "    return rel_(_p)\n",
    "\n",
    "def sa_(x):\n",
    "    als = [\"center\", \"left\", \"right\"]\n",
    "    for o in als:\n",
    "        if o in x:\n",
    "            return x.replace(o, \"_\" + o)\n",
    "    raise ValueError(f\"Bad index contains wrong sensor align: {x}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd8b5f8-92ae-47e4-be33-6d7bf775369f",
   "metadata": {},
   "source": [
    "### Create dataset from sparced ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d14ef5e7-6bc1-477b-af59-ed7356a3d066",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It's important to reduce number of images\n",
    "sparced_ids = [val for i, val in enumerate(bm_ds[\"train_ids\"]) if i % 10 == 0]\n",
    "x_train_dir = np.array([abs_(sensor_p(p, \"camera\")) for p in sparced_ids])\n",
    "y_train_dir = np.array([abs_(sensor_p(p, \"label\")) for p in sparced_ids])\n",
    "\n",
    "# It's important to reduce number of images\n",
    "sparced_val_ids = [val for i, val in enumerate(bm_ds[\"val_ids\"]) if i % 10 == 0]\n",
    "val_images_paths = np.array([abs_(sensor_p(p, \"camera\")) for p in sparced_val_ids])\n",
    "val_labels_paths = np.array([abs_(sensor_p(p, \"label\")) for p in sparced_val_ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2bf7c790-8db2-4543-a54d-7bcdae843f9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class_names = list(class_list.values())\n",
    "class_rgb_values = [[int(i[1:3], 16), int(i[3:5], 16), int(i[5:7], 16)] for i in class_list.keys()]\n",
    "\n",
    "# Useful to shortlist specific classes in datasets with large number of classes\n",
    "select_classes = class_names # all classes\n",
    "\n",
    "# Get RGB values of required classes\n",
    "select_class_indices = [class_names.index(cls) for cls in select_classes]\n",
    "select_class_rgb_values =  np.array(class_rgb_values)[select_class_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65c61d12-3d18-4d1d-8599-9c9826753b4b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class A2D2_Dataset(torch.utils.data.Dataset):\n",
    "\n",
    "    \"\"\"Audi Autonomous Driving Dataset. \n",
    "       Read images, apply augmentation and preprocessing transformations.\n",
    "    \n",
    "    Args:\n",
    "        images_dir (str): path to images folder\n",
    "        masks_dir (str): path to segmentation masks folder\n",
    "        class_rgb_values (list): RGB values of select classes to extract from segmentation mask\n",
    "        augmentation (albumentations.Compose): data transfromation pipeline \n",
    "            (e.g. flip, scale, etc.)\n",
    "        preprocessing (albumentations.Compose): data preprocessing \n",
    "            (e.g. noralization, shape manipulation, etc.)\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "            self, \n",
    "            images_list, \n",
    "            masks_list, \n",
    "            class_rgb_values=None, \n",
    "            augmentation=None, \n",
    "            preprocessing=None,\n",
    "    ):\n",
    "        \n",
    "        self.image_paths = images_list\n",
    "        self.mask_paths = masks_list\n",
    "\n",
    "        self.class_rgb_values = class_rgb_values\n",
    "        self.augmentation = augmentation\n",
    "        self.preprocessing = preprocessing\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        \n",
    "        # read images and masks\n",
    "        image = cv2.cvtColor(cv2.imread(self.image_paths[i]), cv2.COLOR_BGR2RGB)\n",
    "        mask = cv2.cvtColor(cv2.imread(self.mask_paths[i]), cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # one-hot-encode the mask\n",
    "        mask = one_hot_encode(mask, self.class_rgb_values).astype('float')\n",
    "        \n",
    "        # apply augmentations\n",
    "        if self.augmentation:\n",
    "            sample = self.augmentation(image=image, mask=mask)\n",
    "            image, mask = sample['image'], sample['mask']\n",
    "        \n",
    "        # apply preprocessing\n",
    "        if self.preprocessing:\n",
    "            sample = self.preprocessing(image=image, mask=mask)\n",
    "            image, mask = sample['image'], sample['mask']\n",
    "            \n",
    "        return image, mask\n",
    "        \n",
    "    def __len__(self):\n",
    "        # return length of \n",
    "        return len(self.image_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b4549f-4a44-4626-b9e6-a26e2058e55d",
   "metadata": {},
   "source": [
    "### Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1fade33a-c9e2-442b-b5ee-d3f619baeb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_augmentation():\n",
    "    train_transform = [    \n",
    "        album.RandomCrop(height=256, width=256, always_apply=True),\n",
    "        album.OneOf(\n",
    "            [\n",
    "                album.HorizontalFlip(p=1),\n",
    "                album.VerticalFlip(p=1),\n",
    "                album.RandomRotate90(p=1),\n",
    "            ],\n",
    "            p=0.75,\n",
    "        ),\n",
    "    ]\n",
    "    return album.Compose(train_transform)\n",
    "\n",
    "\n",
    "def get_validation_augmentation():   \n",
    "    # Add sufficient padding to ensure image is divisible by 32\n",
    "    test_transform = [\n",
    "        album.PadIfNeeded(min_height=1536, min_width=1536, always_apply=True, border_mode=0),\n",
    "    ]\n",
    "    return album.Compose(test_transform)\n",
    "\n",
    "\n",
    "def to_tensor(x, **kwargs):\n",
    "    return x.transpose(2, 0, 1).astype('float32')\n",
    "\n",
    "\n",
    "def get_preprocessing(preprocessing_fn=None):\n",
    "    \"\"\"Construct preprocessing transform    \n",
    "    Args:\n",
    "        preprocessing_fn (callable): data normalization function \n",
    "            (can be specific for each pretrained neural network)\n",
    "    Return:\n",
    "        transform: albumentations.Compose\n",
    "    \"\"\"   \n",
    "    _transform = []\n",
    "    if preprocessing_fn:\n",
    "        _transform.append(album.Lambda(image=preprocessing_fn))\n",
    "    _transform.append(album.Lambda(image=to_tensor, mask=to_tensor))\n",
    "        \n",
    "    return album.Compose(_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a224dfd5-8d09-43c5-a296-ca239080261f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ENCODER = 'resnet101'\n",
    "ENCODER_WEIGHTS = 'imagenet'\n",
    "CLASSES = class_names\n",
    "ACTIVATION = 'sigmoid' # could be None for logits or 'softmax2d' for multiclass segmentation\n",
    "\n",
    "# create segmentation model with pretrained encoder\n",
    "model = smp.DeepLabV3Plus(\n",
    "    encoder_name=ENCODER, \n",
    "    encoder_weights=ENCODER_WEIGHTS, \n",
    "    classes=len(CLASSES), \n",
    "    activation=ACTIVATION,\n",
    ")\n",
    "\n",
    "preprocessing_fn = smp.encoders.get_preprocessing_fn(ENCODER, ENCODER_WEIGHTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4399ce96-a3ba-4afd-8afe-e8e388d6f6c4",
   "metadata": {},
   "source": [
    "### Define training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "61203e4b-1a51-444c-ab1e-889b25437cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get train and val dataset instances\n",
    "train_dataset = A2D2_Dataset(\n",
    "    x_train_dir, y_train_dir, \n",
    "    augmentation=get_training_augmentation(),\n",
    "    preprocessing=get_preprocessing(preprocessing_fn),\n",
    "    class_rgb_values=select_class_rgb_values,\n",
    ")\n",
    "\n",
    "valid_dataset = A2D2_Dataset(\n",
    "    val_images_paths, val_labels_paths, \n",
    "    augmentation=get_validation_augmentation(), \n",
    "    preprocessing=get_preprocessing(preprocessing_fn),\n",
    "    class_rgb_values=select_class_rgb_values,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c068f880-a7c5-4462-9f70-92d7a216d61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set flag to train the model or not. If set to 'False', only prediction is performed (using an older model checkpoint)\n",
    "TRAINING = True\n",
    "\n",
    "# Set device: `cuda` or `cpu`\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# define loss function\n",
    "loss = smp.utils.losses.DiceLoss()\n",
    "\n",
    "# define metrics\n",
    "metrics = [\n",
    "    smp.utils.metrics.IoU(threshold=0.5),\n",
    "]\n",
    "\n",
    "# define optimizer\n",
    "optimizer = torch.optim.Adam([ \n",
    "    dict(params=model.parameters(), lr=0.0001),\n",
    "])\n",
    "\n",
    "# define learning rate scheduler (not used in this NB)\n",
    "lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "    optimizer, T_0=1, T_mult=2, eta_min=5e-5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "244291b8-ef12-4b79-bdb7-d4f0203896a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load best saved model checkpoint from previous commit (if present)\n",
    "if os.path.exists('best_baseline_model.pth'):\n",
    "    model = torch.load('best_baseline_model.pth', map_location=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2ff2ca41-e58e-4476-9d06-d3c41adb2e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_epoch = smp.utils.train.TrainEpoch(\n",
    "    model, \n",
    "    loss=loss, \n",
    "    metrics=metrics, \n",
    "    optimizer=optimizer,\n",
    "    device=DEVICE,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "valid_epoch = smp.utils.train.ValidEpoch(\n",
    "    model, \n",
    "    loss=loss, \n",
    "    metrics=metrics, \n",
    "    device=DEVICE,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a0fab779-e25f-4913-9703-56299b1dd02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set num of epochs\n",
    "EPOCHS = 5\n",
    "\n",
    "# Get train and val data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True, num_workers=0)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=2, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249be601-5679-4cb2-b358-80fcd0064173",
   "metadata": {},
   "source": [
    "### Run training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "14d492b1-c3d7-4c84-a961-39cd011cb1fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0\n",
      "train: 100%|██████████| 1359/1359 [3:19:44<00:00,  8.82s/it, dice_loss - 0.6505, iou_score - 0.2647] \n",
      "valid: 100%|██████████| 283/283 [59:59<00:00, 12.72s/it, dice_loss - 0.4065, iou_score - 0.4482]\n",
      "Model saved!\n",
      "\n",
      "Epoch: 1\n",
      "train: 100%|██████████| 1359/1359 [3:17:29<00:00,  8.72s/it, dice_loss - 0.4855, iou_score - 0.3918] \n",
      "valid: 100%|██████████| 283/283 [57:58<00:00, 12.29s/it, dice_loss - 0.3594, iou_score - 0.4877]\n",
      "Model saved!\n",
      "\n",
      "Epoch: 2\n",
      "train: 100%|██████████| 1359/1359 [3:18:52<00:00,  8.78s/it, dice_loss - 0.4268, iou_score - 0.4546] \n",
      "valid: 100%|██████████| 283/283 [58:41<00:00, 12.44s/it, dice_loss - 0.3166, iou_score - 0.5333]\n",
      "Model saved!\n",
      "\n",
      "Epoch: 3\n",
      "train: 100%|██████████| 1359/1359 [3:18:03<00:00,  8.74s/it, dice_loss - 0.3857, iou_score - 0.4989] \n",
      "valid: 100%|██████████| 283/283 [58:07<00:00, 12.32s/it, dice_loss - 0.3736, iou_score - 0.479] \n",
      "\n",
      "Epoch: 4\n",
      "train: 100%|██████████| 1359/1359 [3:17:56<00:00,  8.74s/it, dice_loss - 0.3744, iou_score - 0.5046] \n",
      "valid: 100%|██████████| 283/283 [58:10<00:00, 12.34s/it, dice_loss - 0.214, iou_score - 0.6901] \n",
      "Model saved!\n",
      "CPU times: user 1d 53min 57s, sys: 5h 57min 37s, total: 1d 6h 51min 34s\n",
      "Wall time: 21h 25min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "if TRAINING:\n",
    "\n",
    "    best_iou_score = 0.0\n",
    "    train_logs_list, valid_logs_list = [], []\n",
    "\n",
    "    for i in range(0, EPOCHS):\n",
    "\n",
    "        # Perform training & validation\n",
    "        print('\\nEpoch: {}'.format(i))\n",
    "        train_logs = train_epoch.run(train_loader)\n",
    "        valid_logs = valid_epoch.run(valid_loader)\n",
    "        train_logs_list.append(train_logs)\n",
    "        valid_logs_list.append(valid_logs)\n",
    "\n",
    "        # Save model if a better val IoU score is obtained\n",
    "        if best_iou_score < valid_logs['iou_score']:\n",
    "            best_iou_score = valid_logs['iou_score']\n",
    "            torch.save(model, './best_baseline_model.pth')\n",
    "            print('Model saved!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f7ba2771-967c-4480-9468-b9581a51e664",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "score_train = [i[\"iou_score\"] for i in train_logs_list]\n",
    "score_valid = [i[\"iou_score\"] for i in valid_logs_list]\n",
    "\n",
    "ax.plot(score_train, label=\"train IoU\")\n",
    "ax.plot(score_valid, label=\"validation IoU\")\n",
    "ax.set_xticks([i for i in range(5)])\n",
    "\n",
    "plt.suptitle(\"IoU during train\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"IoU\")\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df88b2eb-bcd7-4377-b28e-ef336d9d9619",
   "metadata": {},
   "source": [
    "### Check IoU on the test benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b9885f4e-c4c6-490d-92c3-6fb0f2405f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ids = bm_ds[\"test_ids\"]\n",
    "x_test_dir = np.array([abs_(sensor_p(p, \"camera\")) for p in test_ids])\n",
    "y_test_dir = np.array([abs_(sensor_p(p, \"label\")) for p in test_ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "663f396f-9208-4bf9-8232-b0fa598be9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create test dataloader (with preprocessing operation: to_tensor(...))\n",
    "test_dataset = A2D2_Dataset(\n",
    "    x_test_dir, \n",
    "    y_test_dir, \n",
    "    augmentation=get_validation_augmentation(), \n",
    "    preprocessing=get_preprocessing(preprocessing_fn),\n",
    "    class_rgb_values=select_class_rgb_values,\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8e8acb-4597-467e-b549-dcb28a718222",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51f5587-b5e0-4dce-bfd9-de734d1f2ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "image, gt_mask = test_dataset[0]\n",
    "x_tensor = torch.from_numpy(image).to(DEVICE).unsqueeze(0)\n",
    "\n",
    "pred_mask = model(x_tensor)\n",
    "pred_mask = pred_mask.detach().squeeze().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8185697e-f370-4221-a6aa-d8acff29e162",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a50862-bc82-4fd9-a24f-f054c1b1396f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_mask.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
